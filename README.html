<!DOCTYPE html><html><head>
      <title>README</title>
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/katex.min.css">
      
      
      
      
      
      
      
      
      
      <style>
      /**
 * prism.js Github theme based on GitHub's theme.
 * @author Sam Clarke
 */
code[class*="language-"],
pre[class*="language-"] {
  color: #333;
  background: none;
  font-family: Consolas, "Liberation Mono", Menlo, Courier, monospace;
  text-align: left;
  white-space: pre;
  word-spacing: normal;
  word-break: normal;
  word-wrap: normal;
  line-height: 1.4;

  -moz-tab-size: 8;
  -o-tab-size: 8;
  tab-size: 8;

  -webkit-hyphens: none;
  -moz-hyphens: none;
  -ms-hyphens: none;
  hyphens: none;
}

/* Code blocks */
pre[class*="language-"] {
  padding: .8em;
  overflow: auto;
  /* border: 1px solid #ddd; */
  border-radius: 3px;
  /* background: #fff; */
  background: #f5f5f5;
}

/* Inline code */
:not(pre) > code[class*="language-"] {
  padding: .1em;
  border-radius: .3em;
  white-space: normal;
  background: #f5f5f5;
}

.token.comment,
.token.blockquote {
  color: #969896;
}

.token.cdata {
  color: #183691;
}

.token.doctype,
.token.punctuation,
.token.variable,
.token.macro.property {
  color: #333;
}

.token.operator,
.token.important,
.token.keyword,
.token.rule,
.token.builtin {
  color: #a71d5d;
}

.token.string,
.token.url,
.token.regex,
.token.attr-value {
  color: #183691;
}

.token.property,
.token.number,
.token.boolean,
.token.entity,
.token.atrule,
.token.constant,
.token.symbol,
.token.command,
.token.code {
  color: #0086b3;
}

.token.tag,
.token.selector,
.token.prolog {
  color: #63a35c;
}

.token.function,
.token.namespace,
.token.pseudo-element,
.token.class,
.token.class-name,
.token.pseudo-class,
.token.id,
.token.url-reference .token.variable,
.token.attr-name {
  color: #795da3;
}

.token.entity {
  cursor: help;
}

.token.title,
.token.title .token.punctuation {
  font-weight: bold;
  color: #1d3e81;
}

.token.list {
  color: #ed6a43;
}

.token.inserted {
  background-color: #eaffea;
  color: #55a532;
}

.token.deleted {
  background-color: #ffecec;
  color: #bd2c00;
}

.token.bold {
  font-weight: bold;
}

.token.italic {
  font-style: italic;
}


/* JSON */
.language-json .token.property {
  color: #183691;
}

.language-markup .token.tag .token.punctuation {
  color: #333;
}

/* CSS */
code.language-css,
.language-css .token.function {
  color: #0086b3;
}

/* YAML */
.language-yaml .token.atrule {
  color: #63a35c;
}

code.language-yaml {
  color: #183691;
}

/* Ruby */
.language-ruby .token.function {
  color: #333;
}

/* Markdown */
.language-markdown .token.url {
  color: #795da3;
}

/* Makefile */
.language-makefile .token.symbol {
  color: #795da3;
}

.language-makefile .token.variable {
  color: #183691;
}

.language-makefile .token.builtin {
  color: #0086b3;
}

/* Bash */
.language-bash .token.keyword {
  color: #0086b3;
}

/* highlight */
pre[data-line] {
  position: relative;
  padding: 1em 0 1em 3em;
}
pre[data-line] .line-highlight-wrapper {
  position: absolute;
  top: 0;
  left: 0;
  background-color: transparent;
  display: block;
  width: 100%;
}

pre[data-line] .line-highlight {
  position: absolute;
  left: 0;
  right: 0;
  padding: inherit 0;
  margin-top: 1em;
  background: hsla(24, 20%, 50%,.08);
  background: linear-gradient(to right, hsla(24, 20%, 50%,.1) 70%, hsla(24, 20%, 50%,0));
  pointer-events: none;
  line-height: inherit;
  white-space: pre;
}

pre[data-line] .line-highlight:before, 
pre[data-line] .line-highlight[data-end]:after {
  content: attr(data-start);
  position: absolute;
  top: .4em;
  left: .6em;
  min-width: 1em;
  padding: 0 .5em;
  background-color: hsla(24, 20%, 50%,.4);
  color: hsl(24, 20%, 95%);
  font: bold 65%/1.5 sans-serif;
  text-align: center;
  vertical-align: .3em;
  border-radius: 999px;
  text-shadow: none;
  box-shadow: 0 1px white;
}

pre[data-line] .line-highlight[data-end]:after {
  content: attr(data-end);
  top: auto;
  bottom: .4em;
}html body{font-family:"Helvetica Neue",Helvetica,"Segoe UI",Arial,freesans,sans-serif;font-size:16px;line-height:1.6;color:#333;background-color:#fff;overflow:initial;box-sizing:border-box;word-wrap:break-word}html body>:first-child{margin-top:0}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{line-height:1.2;margin-top:1em;margin-bottom:16px;color:#000}html body h1{font-size:2.25em;font-weight:300;padding-bottom:.3em}html body h2{font-size:1.75em;font-weight:400;padding-bottom:.3em}html body h3{font-size:1.5em;font-weight:500}html body h4{font-size:1.25em;font-weight:600}html body h5{font-size:1.1em;font-weight:600}html body h6{font-size:1em;font-weight:600}html body h1,html body h2,html body h3,html body h4,html body h5{font-weight:600}html body h5{font-size:1em}html body h6{color:#5c5c5c}html body strong{color:#000}html body del{color:#5c5c5c}html body a:not([href]){color:inherit;text-decoration:none}html body a{color:#08c;text-decoration:none}html body a:hover{color:#00a3f5;text-decoration:none}html body img{max-width:100%}html body>p{margin-top:0;margin-bottom:16px;word-wrap:break-word}html body>ul,html body>ol{margin-bottom:16px}html body ul,html body ol{padding-left:2em}html body ul.no-list,html body ol.no-list{padding:0;list-style-type:none}html body ul ul,html body ul ol,html body ol ol,html body ol ul{margin-top:0;margin-bottom:0}html body li{margin-bottom:0}html body li.task-list-item{list-style:none}html body li>p{margin-top:0;margin-bottom:0}html body .task-list-item-checkbox{margin:0 .2em .25em -1.8em;vertical-align:middle}html body .task-list-item-checkbox:hover{cursor:pointer}html body blockquote{margin:16px 0;font-size:inherit;padding:0 15px;color:#5c5c5c;background-color:#f0f0f0;border-left:4px solid #d6d6d6}html body blockquote>:first-child{margin-top:0}html body blockquote>:last-child{margin-bottom:0}html body hr{height:4px;margin:32px 0;background-color:#d6d6d6;border:0 none}html body table{margin:10px 0 15px 0;border-collapse:collapse;border-spacing:0;display:block;width:100%;overflow:auto;word-break:normal;word-break:keep-all}html body table th{font-weight:bold;color:#000}html body table td,html body table th{border:1px solid #d6d6d6;padding:6px 13px}html body dl{padding:0}html body dl dt{padding:0;margin-top:16px;font-size:1em;font-style:italic;font-weight:bold}html body dl dd{padding:0 16px;margin-bottom:16px}html body code{font-family:Menlo,Monaco,Consolas,'Courier New',monospace;font-size:.85em !important;color:#000;background-color:#f0f0f0;border-radius:3px;padding:.2em 0}html body code::before,html body code::after{letter-spacing:-0.2em;content:"\00a0"}html body pre>code{padding:0;margin:0;font-size:.85em !important;word-break:normal;white-space:pre;background:transparent;border:0}html body .highlight{margin-bottom:16px}html body .highlight pre,html body pre{padding:1em;overflow:auto;font-size:.85em !important;line-height:1.45;border:#d6d6d6;border-radius:3px}html body .highlight pre{margin-bottom:0;word-break:normal}html body pre code,html body pre tt{display:inline;max-width:initial;padding:0;margin:0;overflow:initial;line-height:inherit;word-wrap:normal;background-color:transparent;border:0}html body pre code:before,html body pre tt:before,html body pre code:after,html body pre tt:after{content:normal}html body p,html body blockquote,html body ul,html body ol,html body dl,html body pre{margin-top:0;margin-bottom:16px}html body kbd{color:#000;border:1px solid #d6d6d6;border-bottom:2px solid #c7c7c7;padding:2px 4px;background-color:#f0f0f0;border-radius:3px}@media print{html body{background-color:#fff}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{color:#000;page-break-after:avoid}html body blockquote{color:#5c5c5c}html body pre{page-break-inside:avoid}html body table{display:table}html body img{display:block;max-width:100%;max-height:100%}html body pre,html body code{word-wrap:break-word;white-space:pre}}.markdown-preview{width:100%;height:100%;box-sizing:border-box}.markdown-preview .pagebreak,.markdown-preview .newpage{page-break-before:always}.markdown-preview pre.line-numbers{position:relative;padding-left:3.8em;counter-reset:linenumber}.markdown-preview pre.line-numbers>code{position:relative}.markdown-preview pre.line-numbers .line-numbers-rows{position:absolute;pointer-events:none;top:1em;font-size:100%;left:0;width:3em;letter-spacing:-1px;border-right:1px solid #999;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.markdown-preview pre.line-numbers .line-numbers-rows>span{pointer-events:none;display:block;counter-increment:linenumber}.markdown-preview pre.line-numbers .line-numbers-rows>span:before{content:counter(linenumber);color:#999;display:block;padding-right:.8em;text-align:right}.markdown-preview .mathjax-exps .MathJax_Display{text-align:center !important}.markdown-preview:not([for="preview"]) .code-chunk .btn-group{display:none}.markdown-preview:not([for="preview"]) .code-chunk .status{display:none}.markdown-preview:not([for="preview"]) .code-chunk .output-div{margin-bottom:16px}.scrollbar-style::-webkit-scrollbar{width:8px}.scrollbar-style::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}.scrollbar-style::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,0.66);border:4px solid rgba(150,150,150,0.66);background-clip:content-box}html body[for="html-export"]:not([data-presentation-mode]){position:relative;width:100%;height:100%;top:0;left:0;margin:0;padding:0;overflow:auto}html body[for="html-export"]:not([data-presentation-mode]) .markdown-preview{position:relative;top:0}@media screen and (min-width:914px){html body[for="html-export"]:not([data-presentation-mode]) .markdown-preview{padding:2em calc(50% - 457px + 2em)}}@media screen and (max-width:914px){html body[for="html-export"]:not([data-presentation-mode]) .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for="html-export"]:not([data-presentation-mode]) .markdown-preview{font-size:14px !important;padding:1em}}@media print{html body[for="html-export"]:not([data-presentation-mode]) #sidebar-toc-btn{display:none}}html body[for="html-export"]:not([data-presentation-mode]) #sidebar-toc-btn{position:fixed;bottom:8px;left:8px;font-size:28px;cursor:pointer;color:inherit;z-index:99;width:32px;text-align:center;opacity:.4}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] #sidebar-toc-btn{opacity:1}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc{position:fixed;top:0;left:0;width:300px;height:100%;padding:32px 0 48px 0;font-size:14px;box-shadow:0 0 4px rgba(150,150,150,0.33);box-sizing:border-box;overflow:auto;background-color:inherit}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar{width:8px}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,0.66);border:4px solid rgba(150,150,150,0.66);background-clip:content-box}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc a{text-decoration:none}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc ul{padding:0 1.6em;margin-top:.8em}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc li{margin-bottom:.8em}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc ul{list-style-type:none}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{left:300px;width:calc(100% -  300px);padding:2em calc(50% - 457px -  150px);margin:0;box-sizing:border-box}@media screen and (max-width:1274px){html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{width:100%}}html body[for="html-export"]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .markdown-preview{left:50%;transform:translateX(-50%)}html body[for="html-export"]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .md-sidebar-toc{display:none}
/* Please visit the URL below for more information: */
/*   https://shd101wyy.github.io/markdown-preview-enhanced/#/customize-css */

      </style>
    </head>
    <body for="html-export">
      <div class="mume markdown-preview  ">
      <h1 class="mume-header" id="invertedindex">InvertedIndex</h1>

<p>Fall 2022, CIS 612<br>
Lab 4<br>
Bradley Dowling, 2657649</p>
<h1 class="mume-header" id="setup">Setup</h1>

<p>This project is implemented in Julia and Python using PostgreSQL 15 as the database.<br>
Tested on Ubuntu 22.04 x86_64 with Julia 1.8.2, and Python &gt;= 3.7 with NLTK installed.<br>
The code is available at <a href="https://github.com/hairshirt/InvertedIndex.jl">https://github.com/hairshirt/InvertedIndex.jl</a>.<br>
It has a command line interface that can be used with <code>julia -e &quot;InvertedIndex.jl; julia_main()&quot;</code><br>
and can be compiled to a standalone binary using PackageCompiler.jl.</p>
<h1 class="mume-header" id="database-connection">Database Connection</h1>

<p>The State of the Union speeches are loaded into the data base from in memory dataframe objects and retrieved using LibPQ as the connection library.</p>
<pre data-role="codeBlock" data-info="julia" class="language-julia"><span class="token keyword keyword-const">const</span> CONN <span class="token operator">=</span> Ref<span class="token punctuation">{</span>LibPQ<span class="token punctuation">.</span>Connection<span class="token punctuation">}</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

connect<span class="token punctuation">(</span>user<span class="token punctuation">,</span> pass<span class="token punctuation">,</span> host<span class="token punctuation">,</span> port<span class="token punctuation">,</span> dbname<span class="token punctuation">)</span> <span class="token operator">=</span> LibPQ<span class="token punctuation">.</span>Connection<span class="token punctuation">(</span><span class="token string">&quot;dbname=$dbname user=$user password=$pass port=$port host=$host&quot;</span><span class="token punctuation">)</span>

<span class="token keyword keyword-function">function</span> get_table<span class="token punctuation">(</span>conn<span class="token punctuation">,</span> table<span class="token punctuation">;</span> columns<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">&quot;*&quot;</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    columns <span class="token operator">=</span> length<span class="token punctuation">(</span>columns<span class="token punctuation">)</span> <span class="token operator">&gt;</span> <span class="token number">1</span> <span class="token punctuation">?</span> join<span class="token punctuation">(</span>columns<span class="token punctuation">,</span> <span class="token string">&quot;,&quot;</span><span class="token punctuation">)</span> <span class="token punctuation">:</span> first<span class="token punctuation">(</span>columns<span class="token punctuation">)</span>
    q <span class="token operator">=</span> <span class="token string">&quot;&quot;&quot;
        SELECT $(columns) from $(table);
    &quot;&quot;&quot;</span>
    LibPQ<span class="token punctuation">.</span>execute<span class="token punctuation">(</span>conn<span class="token punctuation">,</span> q<span class="token punctuation">)</span> <span class="token operator">|&gt;</span> DataFrame
<span class="token keyword keyword-end">end</span>

<span class="token keyword keyword-function">function</span> load_table<span class="token punctuation">(</span>conn<span class="token punctuation">,</span> df<span class="token punctuation">,</span> table<span class="token punctuation">;</span> column_defs<span class="token operator">=</span>nothing<span class="token punctuation">)</span>
    <span class="token keyword keyword-if">if</span> isnothing<span class="token punctuation">(</span>column_defs<span class="token punctuation">)</span>
        column_defs <span class="token operator">=</span> <span class="token punctuation">[</span>string<span class="token punctuation">(</span>name<span class="token punctuation">,</span> <span class="token string">&quot; TEXT&quot;</span><span class="token punctuation">)</span> <span class="token keyword keyword-for">for</span> name <span class="token keyword keyword-in">in</span> names<span class="token punctuation">]</span>
    <span class="token keyword keyword-end">end</span>
    _ <span class="token operator">=</span> create_table<span class="token punctuation">(</span>conn<span class="token punctuation">,</span> table<span class="token punctuation">,</span> column_defs<span class="token punctuation">)</span>
    dropmissing<span class="token operator">!</span><span class="token punctuation">(</span>df<span class="token punctuation">)</span> <span class="token comment"># just in case</span>
    row_strings <span class="token operator">=</span> <span class="token punctuation">[</span>string<span class="token punctuation">(</span>join<span class="token punctuation">(</span>collect<span class="token punctuation">(</span>row<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">&apos;,&apos;</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">&quot;\n&quot;</span><span class="token punctuation">)</span> <span class="token keyword keyword-for">for</span> row <span class="token keyword keyword-in">in</span> eachrow<span class="token punctuation">(</span>df<span class="token punctuation">)</span><span class="token punctuation">]</span>
    copyin <span class="token operator">=</span> LibPQ<span class="token punctuation">.</span>CopyIn<span class="token punctuation">(</span><span class="token string">&quot;COPY $table FROM STDIN (FORMAT CSV);&quot;</span><span class="token punctuation">,</span> row_strings<span class="token punctuation">)</span>
    LibPQ<span class="token punctuation">.</span>execute<span class="token punctuation">(</span>conn<span class="token punctuation">,</span> copyin<span class="token punctuation">)</span>
<span class="token keyword keyword-end">end</span>

<span class="token keyword keyword-function">function</span> create_table<span class="token punctuation">(</span>conn<span class="token punctuation">,</span> table<span class="token punctuation">,</span> columns<span class="token punctuation">)</span>
    q <span class="token operator">=</span> <span class="token string">&quot;&quot;&quot;
        DROP TABLE IF EXISTS $(table);
        CREATE TABLE IF NOT EXISTS $(table)(
            $(join(columns, &quot;,\n&quot;))
        );
    &quot;&quot;&quot;</span>
    LibPQ<span class="token punctuation">.</span>execute<span class="token punctuation">(</span>conn<span class="token punctuation">,</span> q<span class="token punctuation">)</span>
<span class="token keyword keyword-end">end</span>
</pre><p><img src="images/Initial%20DB%20Connection.png" alt="db connection"></p>
<p>Here is how they appear in PgAdmin4.</p>
<p><img src="images/SOU%20DB.png" alt="sou db"></p>
<p>And pulling them back into a dataframe from the database.</p>
<p><img src="images/Pull%20from%20DB.png" alt="pull db"></p>
<h1 class="mume-header" id="build-dictionary-and-postings-tables">Build Dictionary and Postings Tables</h1>

<p>The dictionary and postings tables are built by sanitizing and stemming all of the input text and collecting all unique terms into an accumulator.<br>
The term and document frequency is tracked, and then the tables are loaded into the database. Tf-idf is used as the weight, and several options are<br>
available for methods of calculating tf and idf.</p>
<pre data-role="codeBlock" data-info="julia" class="language-julia"><span class="token keyword keyword-const">const</span> TERM_FREQUENCIES <span class="token operator">=</span> Ref<span class="token punctuation">(</span>Dict<span class="token punctuation">{</span>AbstractString<span class="token punctuation">,</span>Accumulator<span class="token punctuation">}</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token keyword keyword-function">function</span> build_inverted_index<span class="token punctuation">(</span>df<span class="token punctuation">;</span> id_col1<span class="token operator">=</span><span class="token punctuation">:</span>president<span class="token punctuation">,</span> id_col2<span class="token operator">=</span><span class="token punctuation">:</span>date<span class="token punctuation">,</span> text_col<span class="token operator">=</span><span class="token punctuation">:</span>speech<span class="token punctuation">,</span> tf_method<span class="token operator">=</span>relative_freq<span class="token punctuation">,</span> idf_method<span class="token operator">=</span>inv_doc_freq_smooth<span class="token punctuation">)</span><span class="token punctuation">::</span>NTuple<span class="token punctuation">{</span><span class="token number">2</span><span class="token punctuation">,</span>DataFrame<span class="token punctuation">}</span>
    @info <span class="token string">&quot;initial df size&quot;</span> size<span class="token punctuation">(</span>df<span class="token punctuation">)</span>
    dropmissing<span class="token operator">!</span><span class="token punctuation">(</span>df<span class="token punctuation">,</span> <span class="token punctuation">[</span>id_col1<span class="token punctuation">,</span> id_col2<span class="token punctuation">,</span> text_col<span class="token punctuation">]</span><span class="token punctuation">)</span>
    @info <span class="token string">&quot;Dropped missings: &quot;</span> size<span class="token punctuation">(</span>df<span class="token punctuation">)</span>

    isempty<span class="token punctuation">(</span>df<span class="token punctuation">)</span> <span class="token operator">&amp;&amp;</span> <span class="token keyword keyword-return">return</span> df

    doc_ids <span class="token operator">=</span> string<span class="token punctuation">.</span><span class="token punctuation">(</span>df<span class="token punctuation">[</span><span class="token operator">!</span><span class="token punctuation">,</span> id_col1<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">&quot;_&quot;</span><span class="token punctuation">,</span> df<span class="token punctuation">[</span><span class="token operator">!</span><span class="token punctuation">,</span> id_col2<span class="token punctuation">]</span><span class="token punctuation">)</span>
    @info <span class="token string">&quot;doc_ids&quot;</span> length<span class="token punctuation">(</span>doc_ids<span class="token punctuation">)</span>

    documents <span class="token operator">=</span> replace<span class="token punctuation">.</span><span class="token punctuation">(</span>ch <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token punctuation">(</span>isascii<span class="token punctuation">(</span>first<span class="token punctuation">(</span>ch<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">&amp;&amp;</span> isletter<span class="token punctuation">(</span>first<span class="token punctuation">(</span>ch<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">?</span> ch <span class="token punctuation">:</span> <span class="token string">&quot; &quot;</span><span class="token punctuation">,</span> split<span class="token punctuation">.</span><span class="token punctuation">(</span>lowercase<span class="token punctuation">.</span><span class="token punctuation">(</span>df<span class="token punctuation">[</span><span class="token operator">!</span><span class="token punctuation">,</span> text_col<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">&quot;&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">.</span><span class="token operator">|&gt;</span> join
    @info <span class="token string">&quot;sanitize documents&quot;</span> length<span class="token punctuation">(</span>documents<span class="token punctuation">)</span>

    coll_freq <span class="token operator">=</span> join<span class="token punctuation">(</span>documents<span class="token punctuation">,</span> <span class="token string">&apos; &apos;</span><span class="token punctuation">)</span> <span class="token operator">|&gt;</span> sanitize_text <span class="token operator">|&gt;</span> counter
    @info <span class="token string">&quot;Collection Frequency&quot;</span> length<span class="token punctuation">(</span>coll_freq<span class="token punctuation">)</span>

    terms <span class="token operator">=</span> collect<span class="token punctuation">(</span>keys<span class="token punctuation">(</span>coll_freq<span class="token punctuation">)</span><span class="token punctuation">)</span>
    @info <span class="token string">&quot;Unique terms&quot;</span> length<span class="token punctuation">(</span>terms<span class="token punctuation">)</span>

    dictionary_table <span class="token operator">=</span> build_dictionary_table<span class="token punctuation">(</span>coll_freq<span class="token punctuation">,</span> terms<span class="token punctuation">,</span> documents<span class="token punctuation">;</span> idf_method<span class="token operator">=</span>idf_method<span class="token punctuation">)</span>
    sort<span class="token operator">!</span><span class="token punctuation">(</span>unique<span class="token operator">!</span><span class="token punctuation">(</span>dictionary_table<span class="token punctuation">,</span> <span class="token punctuation">:</span>term<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">:</span>term<span class="token punctuation">)</span>
    @info <span class="token string">&quot;dictionary table&quot;</span> size<span class="token punctuation">(</span>dictionary_table<span class="token punctuation">)</span>

    postings_table <span class="token operator">=</span> build_postings_table<span class="token punctuation">(</span>doc_ids<span class="token punctuation">,</span> documents<span class="token punctuation">;</span> tf_method<span class="token operator">=</span>tf_method<span class="token punctuation">)</span>
    sort<span class="token operator">!</span><span class="token punctuation">(</span>unique<span class="token operator">!</span><span class="token punctuation">(</span>postings_table<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">:</span>doc_id<span class="token punctuation">,</span> <span class="token punctuation">:</span>term<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">:</span>doc_id<span class="token punctuation">,</span> <span class="token punctuation">:</span>term<span class="token punctuation">]</span><span class="token punctuation">)</span>
    dd <span class="token operator">=</span> Dict<span class="token punctuation">(</span>row<span class="token punctuation">.</span>term <span class="token operator">=</span><span class="token operator">&gt;</span> row<span class="token punctuation">.</span>idf <span class="token keyword keyword-for">for</span> row <span class="token keyword keyword-in">in</span> eachrow<span class="token punctuation">(</span>dictionary_table<span class="token punctuation">)</span><span class="token punctuation">)</span>
    postings_table<span class="token punctuation">[</span><span class="token operator">!</span><span class="token punctuation">,</span> <span class="token punctuation">:</span>tfidf<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span>dd<span class="token punctuation">[</span>row<span class="token punctuation">.</span>term<span class="token punctuation">]</span> <span class="token operator">*</span> row<span class="token punctuation">.</span>tf <span class="token keyword keyword-for">for</span> row <span class="token keyword keyword-in">in</span> eachrow<span class="token punctuation">(</span>postings_table<span class="token punctuation">)</span><span class="token punctuation">]</span>
    @info <span class="token string">&quot;postings table&quot;</span> size<span class="token punctuation">(</span>postings_table<span class="token punctuation">)</span>

    dictionary_table<span class="token punctuation">,</span> postings_table
<span class="token keyword keyword-end">end</span>

<span class="token keyword keyword-function">function</span> build_postings_table<span class="token punctuation">(</span>doc_ids<span class="token punctuation">,</span> documents<span class="token punctuation">;</span> tf_method<span class="token operator">=</span>relative_freq<span class="token punctuation">)</span><span class="token punctuation">::</span>DataFrame
    postings <span class="token operator">=</span> Dict<span class="token punctuation">(</span><span class="token punctuation">:</span>term <span class="token operator">=</span><span class="token operator">&gt;</span> String<span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">:</span>doc_id <span class="token operator">=</span><span class="token operator">&gt;</span> String<span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">:</span>termfreq <span class="token operator">=</span><span class="token operator">&gt;</span> Int64<span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">:</span>tf <span class="token operator">=</span><span class="token operator">&gt;</span> Float64<span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token keyword keyword-for">for</span> <span class="token punctuation">(</span>doc_id<span class="token punctuation">,</span> document<span class="token punctuation">)</span> <span class="token keyword keyword-in">in</span> zip<span class="token punctuation">(</span>doc_ids<span class="token punctuation">,</span> documents<span class="token punctuation">)</span>
        <span class="token keyword keyword-if">if</span> <span class="token operator">!</span>haskey<span class="token punctuation">(</span>TERM_FREQUENCIES<span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> doc_id<span class="token punctuation">)</span>
            TERM_FREQUENCIES<span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">[</span>doc_id<span class="token punctuation">]</span> <span class="token operator">=</span> sanitize_text<span class="token punctuation">(</span>document<span class="token punctuation">)</span> <span class="token operator">|&gt;</span> counter
        <span class="token keyword keyword-end">end</span>
        term_freq <span class="token operator">=</span> TERM_FREQUENCIES<span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">[</span>doc_id<span class="token punctuation">]</span>
        <span class="token keyword keyword-for">for</span> <span class="token punctuation">(</span>term<span class="token punctuation">,</span> freq<span class="token punctuation">)</span> <span class="token keyword keyword-in">in</span> term_freq
            push<span class="token operator">!</span><span class="token punctuation">(</span>postings<span class="token punctuation">[</span><span class="token punctuation">:</span>term<span class="token punctuation">]</span><span class="token punctuation">,</span> term<span class="token punctuation">)</span>
            push<span class="token operator">!</span><span class="token punctuation">(</span>postings<span class="token punctuation">[</span><span class="token punctuation">:</span>doc_id<span class="token punctuation">]</span><span class="token punctuation">,</span> doc_id<span class="token punctuation">)</span>
            push<span class="token operator">!</span><span class="token punctuation">(</span>postings<span class="token punctuation">[</span><span class="token punctuation">:</span>termfreq<span class="token punctuation">]</span><span class="token punctuation">,</span> freq<span class="token punctuation">)</span>
            push<span class="token operator">!</span><span class="token punctuation">(</span>postings<span class="token punctuation">[</span><span class="token punctuation">:</span>tf<span class="token punctuation">]</span><span class="token punctuation">,</span> tf<span class="token punctuation">(</span>term<span class="token punctuation">,</span> term_freq<span class="token punctuation">;</span> fn<span class="token operator">=</span>tf_method<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword keyword-end">end</span>
    <span class="token keyword keyword-end">end</span>
    <span class="token keyword keyword-return">return</span> DataFrame<span class="token punctuation">(</span>postings<span class="token punctuation">)</span>
<span class="token keyword keyword-end">end</span>


<span class="token keyword keyword-function">function</span> build_dictionary_table<span class="token punctuation">(</span>coll_freq<span class="token punctuation">,</span> terms<span class="token punctuation">,</span> documents<span class="token punctuation">;</span> idf_method<span class="token operator">=</span>inv_doc_freq_smooth<span class="token punctuation">)</span><span class="token punctuation">::</span>DataFrame
    doc_freq <span class="token operator">=</span> document_frequency<span class="token punctuation">(</span>terms<span class="token punctuation">,</span> Set<span class="token punctuation">.</span><span class="token punctuation">(</span>split<span class="token punctuation">.</span><span class="token punctuation">(</span>documents<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    DataFrame<span class="token punctuation">(</span>Dict<span class="token punctuation">(</span>
        <span class="token punctuation">:</span>term <span class="token operator">=</span><span class="token operator">&gt;</span> terms<span class="token punctuation">,</span>
        <span class="token punctuation">:</span>docfreq <span class="token operator">=</span><span class="token operator">&gt;</span> <span class="token punctuation">[</span>doc_freq<span class="token punctuation">[</span>term<span class="token punctuation">]</span> <span class="token keyword keyword-for">for</span> term <span class="token keyword keyword-in">in</span> terms<span class="token punctuation">]</span><span class="token punctuation">,</span>
        <span class="token punctuation">:</span>idf <span class="token operator">=</span><span class="token operator">&gt;</span> <span class="token punctuation">[</span>idf<span class="token punctuation">(</span>term<span class="token punctuation">,</span> doc_freq<span class="token punctuation">,</span> length<span class="token punctuation">(</span>documents<span class="token punctuation">)</span><span class="token punctuation">,</span> fn<span class="token operator">=</span>idf_method<span class="token punctuation">)</span> <span class="token keyword keyword-for">for</span> term <span class="token keyword keyword-in">in</span> terms<span class="token punctuation">]</span><span class="token punctuation">,</span>
        <span class="token punctuation">:</span>collectionfreq <span class="token operator">=</span><span class="token operator">&gt;</span> <span class="token punctuation">[</span>coll_freq<span class="token punctuation">[</span>term<span class="token punctuation">]</span> <span class="token keyword keyword-for">for</span> term <span class="token keyword keyword-in">in</span> terms<span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword keyword-end">end</span>

<span class="token keyword keyword-function">function</span> document_frequency<span class="token punctuation">(</span>terms<span class="token punctuation">,</span> documents<span class="token punctuation">)</span><span class="token punctuation">::</span>Dict<span class="token punctuation">{</span>String<span class="token punctuation">,</span>Int<span class="token punctuation">}</span>
    doc_freq <span class="token operator">=</span> Dict<span class="token punctuation">{</span>String<span class="token punctuation">,</span>Int<span class="token punctuation">}</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword keyword-for">for</span> term <span class="token keyword keyword-in">in</span> terms
        <span class="token keyword keyword-if">if</span> <span class="token operator">!</span>haskey<span class="token punctuation">(</span>doc_freq<span class="token punctuation">,</span> term<span class="token punctuation">)</span>
            push<span class="token operator">!</span><span class="token punctuation">(</span>doc_freq<span class="token punctuation">,</span> term <span class="token operator">=</span><span class="token operator">&gt;</span> <span class="token number">0</span><span class="token punctuation">)</span>
        <span class="token keyword keyword-end">end</span>
        <span class="token keyword keyword-for">for</span> doc <span class="token keyword keyword-in">in</span> documents
            <span class="token keyword keyword-if">if</span> term &#x2208; doc
                doc_freq<span class="token punctuation">[</span>term<span class="token punctuation">]</span> <span class="token operator">+=</span> <span class="token number">1</span>
            <span class="token keyword keyword-end">end</span>
        <span class="token keyword keyword-end">end</span>
    <span class="token keyword keyword-end">end</span>
    <span class="token keyword keyword-return">return</span> doc_freq
<span class="token keyword keyword-end">end</span>


tf<span class="token punctuation">(</span>term<span class="token punctuation">,</span> term_freq<span class="token punctuation">;</span> fn<span class="token operator">=</span>relative_freq<span class="token punctuation">)</span><span class="token punctuation">::</span>Float64 <span class="token operator">=</span> fn<span class="token punctuation">(</span>term<span class="token punctuation">,</span> term_freq<span class="token punctuation">)</span>


augmented<span class="token punctuation">(</span>term<span class="token punctuation">,</span> term_freq<span class="token punctuation">)</span><span class="token punctuation">::</span>Float64 <span class="token operator">=</span> <span class="token number">0.5</span> <span class="token operator">+</span> <span class="token number">0.5</span> <span class="token operator">*</span> term_freq<span class="token punctuation">[</span>term<span class="token punctuation">]</span> <span class="token operator">/</span> maximum<span class="token punctuation">(</span>values<span class="token punctuation">(</span>term_freq<span class="token punctuation">)</span><span class="token punctuation">)</span>
log_scaled<span class="token punctuation">(</span>term<span class="token punctuation">,</span> term_freq<span class="token punctuation">)</span><span class="token punctuation">::</span>Float64 <span class="token operator">=</span> log10<span class="token punctuation">(</span><span class="token number">1.0</span> <span class="token operator">+</span> term_freq<span class="token punctuation">[</span>term<span class="token punctuation">]</span><span class="token punctuation">)</span>
boolean_freq<span class="token punctuation">(</span>term<span class="token punctuation">,</span> term_freq<span class="token punctuation">)</span><span class="token punctuation">::</span>Float64 <span class="token operator">=</span> iszero<span class="token punctuation">(</span>term_freq<span class="token punctuation">[</span>term<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token punctuation">?</span> <span class="token number">0.0</span> <span class="token punctuation">:</span> <span class="token number">1.0</span>
raw_count<span class="token punctuation">(</span>term<span class="token punctuation">,</span> term_freq<span class="token punctuation">)</span><span class="token punctuation">::</span>Float64 <span class="token operator">=</span> term_freq<span class="token punctuation">[</span>term<span class="token punctuation">]</span>
relative_freq<span class="token punctuation">(</span>term<span class="token punctuation">,</span> term_freq<span class="token punctuation">)</span><span class="token punctuation">::</span>Float64 <span class="token operator">=</span> term_freq<span class="token punctuation">[</span>term<span class="token punctuation">]</span> <span class="token operator">/</span> <span class="token punctuation">(</span>sum<span class="token punctuation">(</span>values<span class="token punctuation">(</span>term_freq<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">-</span> term_freq<span class="token punctuation">[</span>term<span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token keyword keyword-const">const</span> TF_METHODS <span class="token operator">=</span> Dict<span class="token punctuation">{</span>String<span class="token punctuation">,</span>Function<span class="token punctuation">}</span><span class="token punctuation">(</span>
    <span class="token string">&quot;augmented&quot;</span> <span class="token operator">=</span><span class="token operator">&gt;</span> augmented<span class="token punctuation">,</span>
    <span class="token string">&quot;log_scaled&quot;</span> <span class="token operator">=</span><span class="token operator">&gt;</span> log_scaled<span class="token punctuation">,</span>
    <span class="token string">&quot;boolean_freq&quot;</span> <span class="token operator">=</span><span class="token operator">&gt;</span> boolean_freq<span class="token punctuation">,</span>
    <span class="token string">&quot;raw_count&quot;</span> <span class="token operator">=</span><span class="token operator">&gt;</span> raw_count<span class="token punctuation">,</span>
    <span class="token string">&quot;relative_freq&quot;</span> <span class="token operator">=</span><span class="token operator">&gt;</span> relative_freq<span class="token punctuation">,</span>
<span class="token punctuation">)</span>


idf<span class="token punctuation">(</span>term<span class="token punctuation">,</span> doc_freq<span class="token punctuation">,</span> ndocs<span class="token punctuation">;</span> fn<span class="token operator">=</span>inv_doc_freq_smooth<span class="token punctuation">)</span><span class="token punctuation">::</span>Float64 <span class="token operator">=</span> fn<span class="token punctuation">(</span>term<span class="token punctuation">,</span> doc_freq<span class="token punctuation">,</span> ndocs<span class="token punctuation">)</span>

unary<span class="token punctuation">(</span>term<span class="token punctuation">,</span> doc_freq<span class="token punctuation">,</span> ndocs<span class="token punctuation">)</span><span class="token punctuation">::</span>Float64 <span class="token operator">=</span> iszero<span class="token punctuation">(</span>doc_freq<span class="token punctuation">[</span>term<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token punctuation">?</span> <span class="token number">0.0</span> <span class="token punctuation">:</span> <span class="token number">1.0</span>
inv_doc_freq<span class="token punctuation">(</span>term<span class="token punctuation">,</span> doc_freq<span class="token punctuation">,</span> ndocs<span class="token punctuation">)</span><span class="token punctuation">::</span>Float64 <span class="token operator">=</span> log10<span class="token punctuation">(</span>ndocs <span class="token operator">/</span> doc_freq<span class="token punctuation">[</span>term<span class="token punctuation">]</span><span class="token punctuation">)</span>
inv_doc_freq_smooth<span class="token punctuation">(</span>term<span class="token punctuation">,</span> doc_freq<span class="token punctuation">,</span> ndocs<span class="token punctuation">)</span><span class="token punctuation">::</span>Float64 <span class="token operator">=</span> log10<span class="token punctuation">(</span>ndocs <span class="token operator">/</span> <span class="token punctuation">(</span><span class="token number">1.0</span> <span class="token operator">+</span> doc_freq<span class="token punctuation">[</span>term<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1.0</span>
inv_doc_freq_max<span class="token punctuation">(</span>term<span class="token punctuation">,</span> doc_freq<span class="token punctuation">,</span> ndocs<span class="token punctuation">)</span><span class="token punctuation">::</span>Float64 <span class="token operator">=</span> log10<span class="token punctuation">(</span>maximum<span class="token punctuation">(</span>values<span class="token punctuation">(</span>doc_freq<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token punctuation">(</span><span class="token number">1.0</span> <span class="token operator">+</span> doc_freq<span class="token punctuation">[</span>term<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
probabilistic_inv_doc_freq<span class="token punctuation">(</span>term<span class="token punctuation">,</span> doc_freq<span class="token punctuation">,</span> ndocs<span class="token punctuation">)</span><span class="token punctuation">::</span>Float64 <span class="token operator">=</span> log10<span class="token punctuation">(</span><span class="token punctuation">(</span>ndocs <span class="token operator">-</span> doc_freq<span class="token punctuation">[</span>term<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">/</span> doc_freq<span class="token punctuation">[</span>term<span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token keyword keyword-const">const</span> IDF_METHODS <span class="token operator">=</span> Dict<span class="token punctuation">{</span>String<span class="token punctuation">,</span>Function<span class="token punctuation">}</span><span class="token punctuation">(</span>
    <span class="token string">&quot;unary&quot;</span> <span class="token operator">=</span><span class="token operator">&gt;</span> unary<span class="token punctuation">,</span>
    <span class="token string">&quot;inv_doc_freq&quot;</span> <span class="token operator">=</span><span class="token operator">&gt;</span> inv_doc_freq<span class="token punctuation">,</span>
    <span class="token string">&quot;inv_doc_freq_smooth&quot;</span> <span class="token operator">=</span><span class="token operator">&gt;</span> inv_doc_freq_smooth<span class="token punctuation">,</span>
    <span class="token string">&quot;inv_doc_freq_max&quot;</span> <span class="token operator">=</span><span class="token operator">&gt;</span> inv_doc_freq_max<span class="token punctuation">,</span>
    <span class="token string">&quot;probabilistic_inv_doc_freq&quot;</span> <span class="token operator">=</span><span class="token operator">&gt;</span> probabilistic_inv_doc_freq<span class="token punctuation">,</span>
<span class="token punctuation">)</span>

<span class="token keyword keyword-function">function</span> __init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token string">py&quot;&quot;</span>&quot;
    from nltk<span class="token punctuation">.</span>corpus <span class="token keyword keyword-import">import</span> stopwords
    from nltk<span class="token punctuation">.</span>stem <span class="token keyword keyword-import">import</span> PorterStemmer
    from nltk<span class="token punctuation">.</span>tokenize <span class="token keyword keyword-import">import</span> word_tokenize


    def sanitize_text<span class="token punctuation">(</span>text<span class="token punctuation">:</span> str<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> list<span class="token punctuation">[</span>str<span class="token punctuation">]</span><span class="token punctuation">:</span>
        <span class="token string">&apos;&apos;&apos;</span>
        Removes english stop words and suffixes from a string <span class="token keyword keyword-using">using</span> nltk<span class="token punctuation">.</span>
        May require nltk<span class="token punctuation">.</span>download<span class="token punctuation">(</span><span class="token operator">&apos;</span>stopwords<span class="token operator">&apos;</span><span class="token punctuation">)</span> and nltk<span class="token punctuation">.</span>download<span class="token punctuation">(</span><span class="token operator">&apos;</span>punkt<span class="token operator">&apos;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>

        Parameters<span class="token punctuation">:</span>
        text <span class="token punctuation">(</span>str<span class="token punctuation">)</span><span class="token punctuation">:</span> A string

        Returns<span class="token punctuation">:</span>
        list<span class="token punctuation">[</span>str<span class="token punctuation">]</span><span class="token punctuation">:</span> A list of word stems with stop words removed
        <span class="token string">&apos;&apos;&apos;</span>
        stemmer <span class="token operator">=</span> PorterStemmer<span class="token punctuation">(</span><span class="token punctuation">)</span>
        stop_words <span class="token operator">=</span> set<span class="token punctuation">(</span>stopwords<span class="token punctuation">.</span>words<span class="token punctuation">(</span><span class="token operator">&apos;</span>english<span class="token operator">&apos;</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        words <span class="token operator">=</span> list<span class="token punctuation">(</span>filter<span class="token punctuation">(</span>lambda word<span class="token punctuation">:</span> word not <span class="token keyword keyword-in">in</span> stop_words<span class="token punctuation">,</span> word_tokenize<span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword keyword-return">return</span> list<span class="token punctuation">(</span>map<span class="token punctuation">(</span>lambda word<span class="token punctuation">:</span> stemmer<span class="token punctuation">.</span>stem<span class="token punctuation">(</span>word<span class="token punctuation">)</span><span class="token punctuation">,</span> words<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token string">&quot;&quot;</span>&quot;
<span class="token keyword keyword-end">end</span>

sanitize_text<span class="token punctuation">(</span>text<span class="token punctuation">)</span> <span class="token operator">=</span> <span class="token string">py&quot;sanitize_text&quot;</span><span class="token punctuation">(</span>text<span class="token punctuation">)</span>

sanitize_string<span class="token punctuation">(</span>s<span class="token punctuation">)</span> <span class="token operator">=</span> replace<span class="token punctuation">(</span>ch <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token punctuation">(</span>isascii<span class="token punctuation">(</span>first<span class="token punctuation">(</span>ch<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">&amp;&amp;</span> isletter<span class="token punctuation">(</span>first<span class="token punctuation">(</span>ch<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">?</span> ch <span class="token punctuation">:</span> <span class="token string">&quot; &quot;</span><span class="token punctuation">,</span> split<span class="token punctuation">(</span>lowercase<span class="token punctuation">(</span>s<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">&quot;&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">|&gt;</span> join <span class="token operator">|&gt;</span> strip
</pre><p><img src="images/Process%20Initial%20Table.png" alt="build inverted index"></p>
<p><img src="images/Add%20Dictionary%20Table%20to%20DB.png" alt="load dictionary"></p>
<p><img src="images/Add%20Postings%20%20table%20to%20DB.png" alt="load postings"></p>
<h1 class="mume-header" id="build-document-vector">Build Document Vector</h1>

<p>Building a matrix of weights for terms and the documents in which they appear.</p>
<pre data-role="codeBlock" data-info="julia" class="language-julia"><span class="token keyword keyword-function">function</span> build_document_vector<span class="token punctuation">(</span>postings<span class="token punctuation">)</span>
    dvec <span class="token operator">=</span> zeros<span class="token punctuation">(</span>X<span class="token punctuation">(</span>unique<span class="token punctuation">(</span>postings<span class="token punctuation">.</span>term<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> Y<span class="token punctuation">(</span>unique<span class="token punctuation">(</span>postings<span class="token punctuation">.</span>doc_id<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword keyword-for">for</span> row <span class="token keyword keyword-in">in</span> eachrow<span class="token punctuation">(</span>postings<span class="token punctuation">)</span>
        dvec<span class="token punctuation">[</span>X<span class="token punctuation">(</span>At<span class="token punctuation">(</span>row<span class="token punctuation">.</span>term<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> Y<span class="token punctuation">(</span>At<span class="token punctuation">(</span>row<span class="token punctuation">.</span>doc_id<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> row<span class="token punctuation">.</span>tfidf
    <span class="token keyword keyword-end">end</span>
    <span class="token keyword keyword-return">return</span> dvec
<span class="token keyword keyword-end">end</span>

</pre><p><img src="images/Build%20Doc%20Vector.png" alt="Build dvec"></p>
<h1 class="mume-header" id="query-results">Query Results</h1>

<p>Query results are computed by cosine similarity on common terms between the document and the query</p>
<pre data-role="codeBlock" data-info="julia" class="language-julia">cosine_similarity<span class="token punctuation">(</span>A<span class="token punctuation">,</span> B<span class="token punctuation">)</span> <span class="token operator">=</span> <span class="token punctuation">(</span>A &#x22C5; B<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token punctuation">(</span>norm<span class="token punctuation">(</span>A<span class="token punctuation">)</span> <span class="token operator">*</span> norm<span class="token punctuation">(</span>B<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token keyword keyword-function">function</span> query<span class="token punctuation">(</span>keywords<span class="token punctuation">,</span> dvec<span class="token punctuation">)</span>
    isempty<span class="token punctuation">(</span>keywords<span class="token punctuation">)</span> <span class="token operator">&amp;&amp;</span> <span class="token keyword keyword-return">return</span> nothing

    keywords <span class="token operator">=</span> sanitize_string<span class="token punctuation">(</span>keywords<span class="token punctuation">)</span> <span class="token operator">|&gt;</span> sanitize_text
    terms<span class="token punctuation">,</span> docs <span class="token operator">=</span> dvec<span class="token punctuation">.</span>dims
    keywords <span class="token operator">=</span> filter<span class="token punctuation">(</span>&#x2208;<span class="token punctuation">(</span>terms<span class="token punctuation">)</span><span class="token punctuation">,</span> keywords<span class="token punctuation">)</span>

    isempty<span class="token punctuation">(</span>keywords<span class="token punctuation">)</span> <span class="token operator">&amp;&amp;</span> <span class="token keyword keyword-return">return</span> nothing

    kws <span class="token operator">=</span> ones<span class="token punctuation">(</span>Float64<span class="token punctuation">,</span> length<span class="token punctuation">(</span>keywords<span class="token punctuation">)</span><span class="token punctuation">)</span>
    dvec <span class="token operator">=</span> dvec<span class="token punctuation">[</span>X<span class="token punctuation">(</span>At<span class="token punctuation">(</span>keywords<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> Y<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span>

    sim <span class="token operator">=</span> <span class="token number">0.0</span>
    idx <span class="token operator">=</span> nothing
    <span class="token keyword keyword-for">for</span> i <span class="token keyword keyword-in">in</span> <span class="token number">1</span><span class="token punctuation">:</span>length<span class="token punctuation">(</span>docs<span class="token punctuation">)</span>
        s <span class="token operator">=</span> cosine_similarity<span class="token punctuation">(</span>kws<span class="token punctuation">,</span> dvec<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> i<span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token keyword keyword-if">if</span> s <span class="token operator">&gt;</span> sim
            sim <span class="token operator">=</span> s
            idx <span class="token operator">=</span> i
        <span class="token keyword keyword-end">end</span>
    <span class="token keyword keyword-end">end</span>
    <span class="token keyword keyword-return">return</span> docs<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">,</span> sim
<span class="token keyword keyword-end">end</span>
</pre><p><img src="images/Query%20Results.png" alt="query results"></p>

      </div>
      
      
    
    
    
    
    
    
    
    
  
    </body></html>